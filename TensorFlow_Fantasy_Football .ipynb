{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly there are a few helper methods supplied to get data from the current fantasy football website. We will use this in the future during inference with our model created with TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "\n",
    "def get_players():\n",
    "    url = 'https://fantasy.premierleague.com/drf/elements/'\n",
    "    return requests.get(url).json()\n",
    "\n",
    "\n",
    "def get_teams():\n",
    "    url = 'https://fantasy.premierleague.com/drf/teams/'\n",
    "    return requests.get(url).json()\n",
    "\n",
    "\n",
    "def get_goalkeepers():\n",
    "    players = get_players()\n",
    "    goalkeepers = []\n",
    "    for player in players:\n",
    "        if player['element_type'] is 1:\n",
    "            goalkeepers.append(player)\n",
    "    return goalkeepers\n",
    "\n",
    "\n",
    "def get_defenders():\n",
    "    players = get_players()\n",
    "    defenders = []\n",
    "    for player in players:\n",
    "        if player['element_type'] is 2:\n",
    "            defenders.append(player)\n",
    "    return defenders\n",
    "\n",
    "\n",
    "def get_midfielders():\n",
    "    players = get_players()\n",
    "    midfielders = []\n",
    "    for player in players:\n",
    "        if player['element_type'] is 3:\n",
    "            midfielders.append(player)\n",
    "    return midfielders\n",
    "\n",
    "\n",
    "def get_forwards():\n",
    "    players = get_players()\n",
    "    forwards = []\n",
    "    for player in players:\n",
    "        if player['element_type'] is 4:\n",
    "            forwards.append(player)\n",
    "    return forwards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next box, we can load up some data from a previous season (2014/2015) and use it for supervised learning. Note that by using this data with the notion of using the created model on today's and the futures data we implicitly assume that similarities in a single previous season could reoccur in a successive one. This of course could be complete bollocks. \n",
    "\n",
    "Data obtained from:\n",
    "https://www.reddit.com/r/FantasyPL/comments/38197f/i_have_complete_fantasy_premier_league_201415/\n",
    "\n",
    "Rough translation from current api keys (from json) from official website to the old data found at the above Reddit link. Not all of it is clear in terms of the translation but there is some data we can use!\n",
    "```\n",
    "Mins           = minutes\n",
    "Goals          = goals_scored\n",
    "Assists        = assists\n",
    "Clean_Sheets   = clean_sheets\n",
    "Goals_Conceded = goals_conceded\n",
    "Yellow_Cards   = yellow_cards\n",
    "Saves          = saves \n",
    "Bonus          = bonus\n",
    "PPI            = ?\n",
    "BPS            = bps\n",
    "Net_Transfers  = ? transfers_in? transfers_out? transfers_in_event? \n",
    "Value          = ? value_season? \n",
    "Points         = ? event_points? \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ID\n",
      "1 Name\n",
      "2 Team\n",
      "3 Position\n",
      "4 Availability\n",
      "5 Selection\n",
      "6 EA_Index\n",
      "7 Price\n",
      "8 ID\n",
      "9 Week\n",
      "10 Opponent\n",
      "11 Venue\n",
      "12 Mins\n",
      "13 Goals\n",
      "14 Assists\n",
      "15 Clean_Sheets\n",
      "16 Goals_Conceded\n",
      "17 Yellow_Cards\n",
      "18 Red_Cards\n",
      "19 Saves\n",
      "20 Bonus\n",
      "21 PPI\n",
      "22 BPS\n",
      "23 Net_Transfers\n",
      "24 Value\n",
      "25 Points\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "    \n",
    "    \n",
    "def get_concatenated_data():\n",
    "    \"\"\"\n",
    "    Concatenate the data found at the supplied link above\n",
    "    to something a little more convenient.\n",
    "    \"\"\"\n",
    "    def get_file_data(file_path):\n",
    "        rows = []\n",
    "        with open(file_path, encoding='ISO-8859-1') as file:\n",
    "            reader = csv.reader(file, delimiter=',')\n",
    "            for row in reader:\n",
    "                rows.append(row)\n",
    "        return rows\n",
    "    \n",
    "    details = get_file_data('Player_Details.csv')\n",
    "    data = get_file_data('Player_Data.csv')\n",
    "    concatenated_rows = []\n",
    "    \n",
    "    for i, data_row in enumerate(data):\n",
    "        if i != 0:\n",
    "            player_id = data_row[0]\n",
    "            for j, player_row in enumerate(details):\n",
    "                if j != 0:\n",
    "                    if player_row[0] == player_id:\n",
    "                        temp_row = []\n",
    "                        temp_row.extend(player_row)\n",
    "                        temp_row.extend(data_row)\n",
    "                        concatenated_rows.append(temp_row)\n",
    "    return concatenated_rows, details[0] + data[0]\n",
    "           \n",
    "    \n",
    "all_old_data, help_header = get_concatenated_data()\n",
    "\n",
    "for i, value in enumerate(help_header):\n",
    "    print(i, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11033 available training examples.\n",
      "2759 available validation examples.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "desired_indices = [6, 7, 12, 13, 14, 16, 17, 18, 20, 21, 22, 24, 25]\n",
    "desired_player_position = \"Midfielder\"\n",
    "other_desired_player_position = \"Forward\"\n",
    "normalise_data = False\n",
    "\n",
    "\n",
    "def get_desired_data(data, desired_indices, player_position, other_player_position):\n",
    "    \"\"\"\n",
    "    Using the above features create supervised data for\n",
    "    TensorFlow neural networks.\n",
    "    \"\"\"\n",
    "    previous_id = int(data[0][0])\n",
    "    previous_week = int(data[0][9])\n",
    "    previous_value = float(data[0][25])\n",
    "    total_data_size = len(data)\n",
    "    approx_amount_zeros = total_data_size\n",
    "\n",
    "    labels = []\n",
    "    features = []\n",
    "\n",
    "    index = 1\n",
    "    while index < total_data_size:\n",
    "        current_id = int(data[index][0])\n",
    "        current_week = int(data[index][9])\n",
    "        position = data[index][3]\n",
    "\n",
    "        correct_position = position == player_position or position == other_player_position\n",
    "        correct_id = previous_id == current_id\n",
    "        corrent_week = (current_week - 1) == previous_week\n",
    "\n",
    "        if (correct_position and correct_id and corrent_week):\n",
    "            current_value = float(data[index][25])    \n",
    "            if current_value != 0 or index < approx_amount_zeros:\n",
    "                features.append([float(data[index - 1][i]) for i in desired_indices])\n",
    "                labels.append(current_value)\n",
    "                previous_value = current_value\n",
    "        index += 1\n",
    "\n",
    "        previous_id = current_id\n",
    "        previous_week = current_week\n",
    "    return np.array(features), np.array(labels).reshape((-1, 1))\n",
    "\n",
    "features, labels = get_desired_data(all_old_data,\n",
    "                                    desired_indices,\n",
    "                                    desired_player_position,\n",
    "                                    other_desired_player_position)\n",
    "if normalise_data:\n",
    "    features = normalize(features)\n",
    "    labels = normalize(labels)\n",
    "\n",
    "train_split = int(0.8 * len(features))\n",
    "train_x = features[0:train_split]\n",
    "train_y = labels[0:train_split]\n",
    "valid_x = features[:-train_split]\n",
    "valid_y = labels[:-train_split]\n",
    "\n",
    "print(len(train_x), \"available training examples.\")\n",
    "print(len(valid_x), \"available validation examples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 172999  | total loss: \u001b[1m\u001b[32m4.03459\u001b[0m\u001b[0m | time: 0.751s\n",
      "| Adam | epoch: 1000 | loss: 4.03459 - binary_acc: 0.2909 -- iter: 11008/11033\n",
      "Training Step: 173000  | total loss: \u001b[1m\u001b[32m3.77330\u001b[0m\u001b[0m | time: 1.760s\n",
      "| Adam | epoch: 1000 | loss: 3.77330 - binary_acc: 0.2993 | val_loss: 3.84317 - val_acc: 0.4386 -- iter: 11033/11033\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "net = tflearn.input_data(shape=[None, train_x.shape[1]])\n",
    "net = tflearn.fully_connected(net, 120, activation='relu',\n",
    "                              regularizer='L2', weight_decay=0.001)\n",
    "net = tflearn.dropout(net, 0.8)\n",
    "net = tflearn.fully_connected(net, 80, activation='relu',\n",
    "                              regularizer='L2', weight_decay=0.001)\n",
    "net = tflearn.dropout(net, 0.8)\n",
    "net = tflearn.fully_connected(net, 1, activation='linear')\n",
    "\n",
    "net = tflearn.regression(net, optimizer='adam', loss='mean_square')\n",
    "\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(train_x, train_y, n_epoch=1000, validation_set=(valid_x, valid_y), \n",
    "          shuffle=True, show_metric=True, run_id=\"dense_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2759 total predictions\n",
      "2069 predictions with under 1 distance\n",
      "\n",
      "1.0561 is the mean prediction\n",
      "5.29215 is the max prediction\n",
      "-0.0456786 is the min prediction\n",
      "\n",
      "0.908034029107 is the mean difference between prediction and target value\n",
      "21.0683026314 is the max difference between prediction and target value\n",
      "0.00282788276672 is the min difference between prediction and target value\n",
      "\n",
      "0.511841469309 is the mean value to be predicted when prediction is very close\n",
      "5.0 is the max value to be predicted when prediction is very close\n",
      "0.0 is the min value to be predicted when prediction is very close\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGQCS1CkDQJI6ZQBIUqf+Hyk5Yuxj23WeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24c4983780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "predictions = model.predict(valid_x)\n",
    "dist = 1\n",
    "differences = []\n",
    "under_one_difference = []\n",
    "for i, prediction in enumerate(predictions):\n",
    "    diff = abs(prediction - valid_y[i])\n",
    "    differences.append(diff)\n",
    "    if (diff <= dist):\n",
    "        under_one_difference.append(valid_y[i])\n",
    "        \n",
    "differences = np.array(differences).reshape(-1).tolist()\n",
    "under_one_difference = np.array(under_one_difference).reshape(-1).tolist()\n",
    "\n",
    "print(len(differences), \"total predictions\")\n",
    "print(len(under_one_difference), \"predictions with under\", dist, \"distance\\n\")\n",
    "print(np.mean(predictions), \"is the mean prediction\")\n",
    "print(np.max(predictions), \"is the max prediction\")\n",
    "print(np.min(predictions), \"is the min prediction\\n\")\n",
    "print(np.mean(differences), \"is the mean difference between prediction and target value\")\n",
    "print(np.max(differences), \"is the max difference between prediction and target value\")\n",
    "print(np.min(differences), \"is the min difference between prediction and target value\\n\")\n",
    "print(np.mean(under_one_difference), \"is the mean value to be predicted when prediction is very close\")\n",
    "print(np.max(under_one_difference), \"is the max value to be predicted when prediction is very close\")\n",
    "print(np.min(under_one_difference), \"is the min value to be predicted when prediction is very close\")\n",
    "\n",
    "_ = plt.hist(differences, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can some times be hard to beat choosing values completely randomly, so I did that to show the neural network is learning something. \n",
    "\n",
    "It is relatively clear here that the random selection histogram shows vast amounts of difference between the prediction and actual when predicting random values in the range of the labels min and max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2759 total predictions\n",
      "204 predictions with under 1 distance\n",
      "\n",
      "1.0561 is the mean prediction\n",
      "5.29215 is the max prediction\n",
      "-0.0456786 is the min prediction\n",
      "\n",
      "10.4668050463 is the mean difference between prediction and target value\n",
      "23.9864054965 is the max difference between prediction and target value\n",
      "0.00134899484294 is the min difference between prediction and target value\n",
      "\n",
      "1.41176470588 is the mean value to be predicted when prediction is very close\n",
      "16.0 is the max value to be predicted when prediction is very close\n",
      "0.0 is the min value to be predicted when prediction is very close\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f24c4ab0dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_predictions = np.random.uniform(np.min(labels), np.max(labels), valid_y.shape)\n",
    "dist = 1\n",
    "differences = []\n",
    "under_one_difference = []\n",
    "for i, prediction in enumerate(random_predictions):\n",
    "    diff = abs(prediction - valid_y[i])\n",
    "    differences.append(diff)\n",
    "    if (diff <= dist):\n",
    "        under_one_difference.append(valid_y[i])\n",
    "        \n",
    "differences = np.array(differences).reshape(-1).tolist()\n",
    "under_one_difference = np.array(under_one_difference).reshape(-1).tolist()\n",
    "\n",
    "print(len(differences), \"total predictions\")\n",
    "print(len(under_one_difference), \"predictions with under\", dist, \"distance\\n\")\n",
    "print(np.mean(predictions), \"is the mean prediction\")\n",
    "print(np.max(predictions), \"is the max prediction\")\n",
    "print(np.min(predictions), \"is the min prediction\\n\")\n",
    "print(np.mean(differences), \"is the mean difference between prediction and target value\")\n",
    "print(np.max(differences), \"is the max difference between prediction and target value\")\n",
    "print(np.min(differences), \"is the min difference between prediction and target value\\n\")\n",
    "print(np.mean(under_one_difference), \"is the mean value to be predicted when prediction is very close\")\n",
    "print(np.max(under_one_difference), \"is the max value to be predicted when prediction is very close\")\n",
    "print(np.min(under_one_difference), \"is the min value to be predicted when prediction is very close\")\n",
    "_ = plt.hist(differences, bins=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
